\newpage
\section{Заключение}

\begin{table}[h!t]
\begin{center}
\caption{Результаты экспериментов}
\label{table_2}
\resizebox{\linewidth}{!}{%
\begin{tabular}{|c|c|c|c|c|}
\hline
	Ученик & Учитель & Связь $\varphi$ & Точность & Кросс-энтропия\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Train}
	& --- & --- & 0{,}879 \pm& 0{,}376\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Train}
	& FashionMNIST & --- & 0{,}884 & 0.332\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& --- & --- & 0.796 & 0.616\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& FashionMNIST-Big & --- & 0.812 & 0.560\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& FashionMNIST-Big& Noise & 0.811 & 0.563\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& FashionMNIST-Big & Dilation & 0.804 & 0.576\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& MNIST-Big & VAE& 0.804 & 0.625\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& MNIST-Big & ---& 0.480 & 1.241\\
	\hline
	\multicolumn{1}{|l|}{FashionMNIST-Small}
	& GeneratedMNIST-Big & VAE & 0.806 & 0.576\\
\hline

\end{tabular}}
\end{center}
\end{table}

В работе исследована проблема понижения сложности модели при ее переносе к новым данным меньшей мощности.
Рассмотрены методы дистилляции моделей и доменной адаптации.
Был предложен подход для случая, когда модели учителя и ученика заданы на выборках разной мощности с известной связью между выборками.

В ходе экспериментов, проведенных на реальных и синтетических данных, показано что предложенные методы хорошо работают для передачи знаний от большой модели к меньшей дистиллированной модели.
Результаты экспериментов представлены в таблице~\ref{table_2}.